# "íŠ¸ë ˆì´ë”© ëŒ€ì‹œë³´ë“œ ì›¹ ì„œë²„ (Flask / Supabase / ê³µìš© ë¦¬í¬íŠ¸)

#  - Flask ê¸°ë°˜ ì›¹ ì•±ìœ¼ë¡œ, Supabase(Postgres)ì— ì €ì¥ëœ trades / logs / signals / models / backtests / ohlcv_data
#    ë¥¼ ì½ì–´ì™€ ì—¬ëŸ¬ í˜ì´ì§€(ìš”ì•½, Universe, ML ëª¨ë‹ˆí„°ë§, ì‹¬ë³¼ ì°¨íŠ¸, ìë™ë§¤ë§¤ ë¡œê·¸, AI ë¦¬í¬íŠ¸)ë¥¼ ë Œë”ë§í•˜ëŠ” ëŒ€ì‹œë³´ë“œ ì„œë²„

# ì£¼ìš” ê¸°ëŠ¥:
# 1) DB ì„¤ì • ë° ê³µìš© ë°ì´í„° ë¡œë”©
#    - Supabase ì ‘ì† ì •ë³´(DB_HOST/DB_NAME/DB_USER/DB_PASS/DB_PORT) ì •ì˜ í›„, ë¹„ë°€ë²ˆí˜¸ë¥¼ URLì— ì•ˆì „í•˜ê²Œ ë„£ê¸° ìœ„í•´ quote_plusë¡œ ì¸ì½”ë”©
#    - DB_URLì„ ë§Œë“¤ì–´ BotDatabase(DB_URL)ì™€ ì—°ë™
#    - common.dash_data ëª¨ë“ˆì˜ get_connection / load_trades / load_logs / load_signals / load_model_versions /
#      load_backtests / load_signals_by_date / load_trades_by_date / build_round_trades / load_ml_signals /
#      suggest_improvements / get_symbols_with_data ë¥¼ ì¬ì‚¬ìš©
#    - dash_universe_ohlcv ì˜ get_universe_coverage / get_last_universe_backfill_time / get_recent_backfill_failures ë¥¼ ì‚¬ìš©í•´
#      Universe OHLCV ìƒíƒœì™€ ë°±í•„ ì‹¤íŒ¨ ë‚´ì—­ ë¡œë”©

# 2) ê³µí†µ ìœ í‹¸ + ëŒ€ì‹œë³´ë“œìš© ì§‘ê³„ (load_all_dashboard_data)
#    - normalize_region(region_raw): ALL/KR/US/CR ì¤‘ í•˜ë‚˜ë¡œ ì •ê·œí™”
#    - filter_by_region(region, df): region ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ DataFrame í•„í„°ë§
#    - load_all_dashboard_data(region_raw):
#      Â· trades/logs/signals/model_versions/backtests/universe_cov/universe_failures ë¥¼ ëª¨ë‘ ë¡œë“œ í›„ regionë³„ í•„í„° ì ìš©
#      Â· trades ê¸°ì¤€ ì„±ê³¼ ìš”ì•½(summary): ì´ íŠ¸ë ˆì´ë“œ ìˆ˜, ìŠ¹ë¥ , í‰ê·  ìˆ˜ìµë¥ , ëˆ„ì  ìˆ˜ìµë¥ (cum_return_pct)
#      Â· ì—ì¿¼í‹° ì»¤ë¸Œ(equity_curve): ì‹œê°„/ëˆ„ì  ìˆ˜ìµë¥ (%) ì‹œê³„ì—´
#      Â· symbols_avg: ì‹¬ë³¼ë³„ í‰ê·  ìˆ˜ìµë¥  ë­í‚¹
#      Â· daily_summaries: ë‚ ì§œë³„ íŠ¸ë ˆì´ë“œ ìˆ˜, ìŠ¹ë¥ , í‰ê·  ìˆ˜ìµë¥ , ì¼ë³„ ëˆ„ì  ìˆ˜ìµë¥ 
#      Â· round_trades_df / round_details: build_round_tradesë¡œ í¬ì§€ì…˜ ë‹¨ìœ„ ë¼ìš´ë“œ íŠ¸ë ˆì´ë“œ êµ¬ì¡° ìƒì„±
#      Â· Universe í†µê³„: ì¢…ëª© ìˆ˜, ì´ ìº”ë“¤ ìˆ˜, ìµœëŒ€ ì»¤ë²„ ì¼ìˆ˜
#      Â· ì˜¤ëŠ˜(or ìµœê·¼) ì‹ í˜¸/íŠ¸ë ˆì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ suggest_improvements í˜¸ì¶œ â†’ ì„¤ì •/ì „ëµ ê°œì„ ì— ëŒ€í•œ í•œêµ­ì–´ í”¼ë“œë°± ë¦¬ìŠ¤íŠ¸(suggestions)
#      Â· ML ëª¨ë‹ˆí„°ë§ìš©: ml_signals ë¡œë¶€í„°
#        - histogram(ml_hist_labels / ml_hist_counts),
#        - ì‹œê³„ì—´(ml_time_series: time / proba / entry_allowed)
#      Â· ì‹¬ë³¼ ì„ íƒìš©: get_symbols_with_data ë¡œ symbols_with_data ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# 3) ì•± ì²´ê²° ë™ê¸°í™” ê´€ë ¨ API
#    - /sync-app-trades (POST): í˜„ì¬ëŠ” stub(sync_app_trades â†’ 0) í˜•íƒœ, í–¥í›„ ì•± ì²´ê²° ë°ì´í„° ì—°ë™ìš© í™•ì¥ í¬ì¸íŠ¸
#    - /sync_app_fills (POST): zz_import_app_fills.sync_app_fills_main() í˜¸ì¶œí•˜ì—¬ ì•± ì²´ê²° ë‚´ì—­ì„ DBì— ë™ê¸°í™”í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸

# 4) ì‹¬ë³¼ ì°¨íŠ¸ìš© ë°ì´í„° API (/symbol_data)
#    - ì¿¼ë¦¬ìŠ¤íŠ¸ë§ symbol(í•„ìˆ˜), region(ì˜µì…˜)ì„ ë°›ê³ 
#    - ohlcv_dataì—ì„œ í•´ë‹¹ ì‹¬ë³¼ì˜ 5ë¶„ë´‰ ìº”ë“¤(dt, open/high/low/close)ë¥¼ ìµœëŒ€ 500ê°œ ë¡œë“œ
#    - trades í…Œì´ë¸”ì—ì„œ ê°™ì€ ì‹¬ë³¼ì˜ ì²´ê²°(time, type, price, qty)ë¥¼ ë¡œë“œ
#    - ìº”ë“¤ ì‹œê³„ì—´(dt) ê¸°ì¤€ìœ¼ë¡œ ê° íŠ¸ë ˆì´ë“œê°€ ì–´ëŠ ìº”ë“¤ ì¸ë±ìŠ¤(x_index)ì— í•´ë‹¹í•˜ëŠ”ì§€ ë§¤í•‘
#    - candles ë¦¬ìŠ¤íŠ¸(ì‹œê°/ê°€ê²©)ì™€ trades ë¦¬ìŠ¤íŠ¸(ìº”ë“¤ ì¸ë±ìŠ¤/ì‹œê°/type/price/qty)ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜ â†’ í”„ë¡ íŠ¸ ì°¨íŠ¸ì—ì„œ ë§¤ìˆ˜/ë§¤ë„ ë§ˆì»¤ í‘œì‹œìš©

# 5) AI ë¦¬í¬íŠ¸ API (/api/ai-report/full)
#    - ai_reports í…Œì´ë¸”ì—ì„œ ìµœì‹  1ê±´(date, created_at, daily_report, strategy_ideas) ì¡°íšŒ
#    - ë¡œì»¬ reports í´ë”ì˜ *_model_advice.txt ì¤‘ ìµœì‹  íŒŒì¼ì„ ì°¾ì•„ model_advice_date + model_advice í…ìŠ¤íŠ¸ ë¡œë“œ
#    - ì´ ë‘˜ì„ í•©ì³ ì¼ê°„ AI ë¦¬í¬íŠ¸ + ëª¨ë¸ ì¡°ì–¸ì„ í•œ ë²ˆì— ë°˜í™˜í•˜ëŠ” JSON API

# 6) í˜ì´ì§€ ë¼ìš°íŠ¸ (Flask í…œí”Œë¦¿ ë Œë”)
#    - ë£¨íŠ¸(/): region ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ë¥¼ ì •ê·œí™” í›„ /dash/overviewë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
#    - /dash/overview:
#      Â· ìš”ì•½/ì„±ëŠ¥ í˜ì´ì§€: summary, equity_curve, symbols_avg, suggestions ë Œë”
#    - /dash/ai-report:
#      Â· AI ë¦¬í¬íŠ¸ í˜ì´ì§€: regionë§Œ ë„˜ê¸°ê³  ì‹¤ì œ ë¦¬í¬íŠ¸ ë‚´ìš©ì€ í”„ë¡ íŠ¸ì—ì„œ APIë¥¼ í˜¸ì¶œí•´ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ì„¤ê³„ ê°€ëŠ¥
#    - /dash/trades, /dash/logs:
#      Â· ê°ê° /dash/autoë¡œ regionë§Œ ë°”ê¿” ë¦¬ë‹¤ì´ë ‰íŠ¸ (ìë™ë§¤ë§¤ íƒ­ì—ì„œ í†µí•© ê´€ë¦¬)
#    - /dash/universe:
#      Â· Universe OHLCV íƒ­: universe_cov, last_universe_backfill, universe_failures, universe í†µê³„ ìˆ«ì ë Œë”
#    - /dash/ml:
#      Â· ML ëª¨ë‹ˆí„°ë§ íƒ­: ML íˆìŠ¤í† ê·¸ë¨/ì‹œê³„ì—´, ëª¨ë¸ ë²„ì „ ë¦¬ìŠ¤íŠ¸, ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë Œë”
#    - /dash/symbols:
#      Â· ì¢…ëª©ë³„ ì°¨íŠ¸ íƒ­: symbols_with_data ë¦¬ìŠ¤íŠ¸ë¥¼ í…œí”Œë¦¿ì— ì „ë‹¬ â†’ ì‚¬ìš©ì ì„ íƒ í›„ /symbol_data APIë¡œ ì°¨íŠ¸ ê·¸ë¦¬ê¸°
#    - /dash/auto:
#      Â· ìë™ë§¤ë§¤ íƒ­:
#        - round_trades / round_details: í¬ì§€ì…˜ ë‹¨ìœ„ ë‚´ì—­
#        - daily_summaries / summary: ì¼ë³„/ì „ì²´ ì„±ê³¼ ìš”ì•½
#        - logs_recent / signals: ìµœê·¼ ë¡œê·¸ì™€ ì—”íŠ¸ë¦¬/ML ì‹ í˜¸ ëª©ë¡
#        - universe_failures: ë°±í•„ ì‹¤íŒ¨ ëª©ë¡ê¹Œì§€ í†µí•© í‘œì‹œ

# 7) ê°œë°œ ì„œë²„ ì‹¤í–‰
#    - __main__ ë¸”ë¡ì—ì„œ app.run(debug=True, port=8000)ìœ¼ë¡œ ë¡œì»¬ ê°œë°œìš© ì‹¤í–‰

from flask import Flask, render_template, jsonify, request, redirect
import os
import psycopg2
import pandas as pd
import numpy as np
from glob import glob
from datetime import date
from urllib.parse import quote_plus  # [ì¶”ê°€] íŠ¹ìˆ˜ë¬¸ì ë¹„ë²ˆ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”

# ê¸°ì¡´ íŒŒì¼ë“¤ import
from c_db_manager import BotDatabase
from d_web_universe_ohlcv import (
    get_universe_coverage,
    get_last_universe_backfill_time,
    get_recent_backfill_failures,
)
# dash_dataì—ì„œ get_connectionì„ ê°€ì ¸ì™€ì„œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤
from d_web_data import (
    get_connection, 
    load_trades,
    load_logs,
    load_signals,
    load_model_versions,
    load_backtests,
    load_signals_by_date,
    load_trades_by_date,
    build_round_trades,
    load_ml_signals,
    suggest_improvements,
    get_symbols_with_data,
)

app = Flask(__name__)

# -----------------------------------------------------------
# [ì¤‘ìš”] dash_data.pyì™€ ë˜‘ê°™ì´ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”
# -----------------------------------------------------------
DB_HOST = "aws-1-ap-northeast-2.pooler.supabase.com"
DB_NAME = "postgres"
DB_USER = "postgres.sxhtnkxulfrqykrtwxjx"  # [ì£¼ì˜] ì•„ì´ë””ê°€ ì´ë ‡ê²Œ ê¸¸ì–´ì§‘ë‹ˆë‹¤
DB_PASS = "Shitdog205!@"                     # ê¸°ì¡´ ë¹„ë°€ë²ˆí˜¸ ê·¸ëŒ€ë¡œ
DB_PORT = "6543"                             # [ì£¼ì˜] í¬íŠ¸ê°€ 6543ì…ë‹ˆë‹¤
# -----------------------------------------------------------

# [í•µì‹¬] íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì•ˆì „í•˜ê²Œ ë³€í™˜í•˜ì—¬ DB_URL ìƒì„±
# (BotDatabase í´ë˜ìŠ¤ê°€ ì´ URLì„ í•„ìš”ë¡œ í•¨)
encoded_pass = quote_plus(DB_PASS)
DB_URL = f"postgresql://{DB_USER}:{encoded_pass}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# -----------------------------
# ê³µí†µ ìœ í‹¸
# -----------------------------
def normalize_region(region_raw: str) -> str:
    region = (region_raw or "ALL").upper()
    if region not in ("ALL", "KR", "US", "CR","BI"):
        region = "ALL"
    return region


def filter_by_region(region: str, df):
    if df is None or len(getattr(df, "columns", [])) == 0:
        return df
    if "region" not in df.columns:
        return df
    if region == "ALL":
        return df
    return df[df["region"] == region].copy()


def load_all_dashboard_data(region_raw: str):
    """
    ëª¨ë“  í˜ì´ì§€ì—ì„œ ì¬ì‚¬ìš©í•  ê³µí†µ ë°ì´í„° ë¡œë”©/ì§‘ê³„ í•¨ìˆ˜
    """
    region = normalize_region(region_raw)

    trades = load_trades()
    logs = load_logs()
    signals = load_signals(limit=200)
    model_versions = load_model_versions()
    backtests = load_backtests(limit=50)

    universe_cov = get_universe_coverage()
    
    # [ìˆ˜ì •] ì•ˆì „í•˜ê²Œ ë§Œë“  DB_URLì„ ì‚¬ìš©í•˜ì—¬ BotDatabase ì—°ê²°
    last_universe_backfill = get_last_universe_backfill_time(db=BotDatabase(DB_URL))
    
    universe_failures = get_recent_backfill_failures(limit=30)

    # region í•„í„° ì ìš©
    trades = filter_by_region(region, trades)
    logs = filter_by_region(region, logs)
    signals = filter_by_region(region, signals)
    model_versions = filter_by_region(region, model_versions)
    backtests = filter_by_region(region, backtests)
    universe_cov = filter_by_region(region, universe_cov)
    universe_failures = filter_by_region(region, universe_failures)

    if not universe_cov.empty:
        universe_cov = universe_cov.sort_values("candles", ascending=False)

    # ë¼ìš´ë“œ íŠ¸ë ˆì´ë“œ
    if region == "BI":
        # ğŸ”¹ BinanceëŠ” positions ê¸°ì¤€ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        round_trades_df = build_round_trades_from_positions(region)
        round_details = {}  # BIëŠ” ìƒì„¸ êµ¬ì¡° ì•„ì§ ì•ˆ ì“°ë©´ ë¹ˆ dict
    else:
        # ê¸°ì¡´ KR/US/CRì€ trades ê¸°ë°˜ ë¼ìš´ë“œ ë¡œì§ ê·¸ëŒ€ë¡œ ìœ ì§€
        if not trades.empty:
            round_trades_df, round_details = build_round_trades(trades)
        else:
            round_trades_df, round_details = pd.DataFrame(), {}

    # Universe ìˆ«ì
    if not universe_cov.empty:
        num_universe_symbols = int(len(universe_cov))
        total_universe_candles = int(universe_cov["candles"].sum())
        max_days_covered = int(universe_cov["days_covered"].max())
    else:
        num_universe_symbols = 0
        total_universe_candles = 0
        max_days_covered = 0

    # ìš”ì•½/ì—ì¿¼í‹°/ì‹¬ë³¼ í‰ê· /ì¼ë³„ ìš”ì•½
    summary = {
        "total_trades": 0,
        "win_rate": 0.0,
        "avg_profit": 0.0,
        "cum_return_pct": 0.0,
    }
    equity_curve = []
    symbols_avg = []
    daily_summaries = []

    if not trades.empty:
        trades_sorted = trades.sort_values("time").copy()

        total_trades = len(trades_sorted)
        wins = trades_sorted[trades_sorted["profit"] > 0]
        win_rate = len(wins) / total_trades * 100
        avg_profit = trades_sorted["profit"].mean()

        cum_return = (1 + trades_sorted["profit"] / 100).cumprod() - 1
        last_cum = float(cum_return.iloc[-1]) if len(cum_return) > 0 else 0.0

        summary = {
            "total_trades": total_trades,
            "win_rate": round(win_rate, 2),
            "avg_profit": round(avg_profit, 2),
            "cum_return_pct": round(last_cum * 100, 2),
        }

        trades_sorted["cum_return"] = cum_return
        equity_curve = [
            {
                "time": t.strftime("%Y-%m-%d %H:%M"),
                "value": float(v * 100),
            }
            for t, v in zip(trades_sorted["time"], trades_sorted["cum_return"])
        ]

        by_symbol = trades.groupby("symbol")["profit"].mean().sort_values(ascending=False)
        symbols_avg = [
            {"symbol": s, "avg_profit": float(p)}
            for s, p in by_symbol.items()
        ]

        tmp = trades_sorted.copy()
        tmp["date"] = tmp["time"].dt.strftime("%Y-%m-%d")

        for d, df_day in tmp.groupby("date"):
            n = len(df_day)
            wins_day = (df_day["profit"] > 0).sum()
            win_rate_day = (wins_day / n * 100) if n > 0 else 0.0
            avg_profit_day = df_day["profit"].mean() if n > 0 else 0.0
            cum_ret_day = (1 + df_day["profit"] / 100).prod() - 1

            daily_summaries.append({
                "date": d,
                "total_trades": int(n),
                "win_rate": round(win_rate_day, 2),
                "avg_profit": round(avg_profit_day, 2),
                "cum_return_pct": round(cum_ret_day * 100, 2),
            })

        daily_summaries.sort(key=lambda x: x["date"], reverse=True)

    logs_recent = logs.head(200) if not logs.empty else pd.DataFrame()

    # ì˜¤ëŠ˜ ê¸°ì¤€ ì‹ í˜¸/íŠ¸ë ˆì´ë“œ
    today_str = date.today().strftime("%Y-%m-%d")
    today_signals = filter_by_region(region, load_signals_by_date(today_str))
    today_trades = filter_by_region(region, load_trades_by_date(today_str))

    if today_signals.empty:
        today_signals = filter_by_region(region, load_signals(limit=200))

    suggestions = suggest_improvements(
        df_sig=today_signals,
        df_tr=today_trades,
        ml_threshold=0.55,
    )

    # ML ëª¨ë‹ˆí„°ë§ìš©
    ml_signals = filter_by_region(region, load_ml_signals(limit=500))

    ml_hist_labels = []
    ml_hist_counts = []
    ml_time_series = []

    if not ml_signals.empty:
        bins = np.linspace(0, 1, 11)
        ml_signals["bin"] = pd.cut(
            ml_signals["ml_proba"],
            bins=bins,
            include_lowest=True,
            right=False,
        )

        bin_counts = ml_signals["bin"].value_counts().sort_index()

        ml_hist_labels = [
            f"{interval.left:.1f}~{interval.right:.1f}"
            for interval in bin_counts.index
        ]
        ml_hist_counts = [int(c) for c in bin_counts.values]

        ml_time_series = [
            {
                "time": t.strftime("%Y-%m-%d %H:%M"),
                "proba": float(p),
                "entry_allowed": int(e) if pd.notna(e) else 0,
            }
            for t, p, e in zip(
                ml_signals["time"],
                ml_signals["ml_proba"],
                ml_signals["entry_allowed"].fillna(0),
            )
        ]

    symbols_with_data = get_symbols_with_data(trades)

    return {
        "region": region,
        "summary": summary,
        "equity_curve": equity_curve,
        "symbols_avg": symbols_avg,
        "trades": trades,
        "logs_recent": logs_recent,
        "signals": signals,
        "model_versions": model_versions,
        "backtests": backtests,
        "universe_cov": universe_cov,
        "last_universe_backfill": last_universe_backfill,
        "universe_failures": universe_failures,
        "num_universe_symbols": num_universe_symbols,
        "total_universe_candles": total_universe_candles,
        "max_days_covered": max_days_covered,
        "round_trades_df": round_trades_df,
        "round_details": round_details,
        "daily_summaries": daily_summaries,
        "suggestions": suggestions,
        "ml_hist_labels": ml_hist_labels,
        "ml_hist_counts": ml_hist_counts,
        "ml_time_series": ml_time_series,
        "symbols_with_data": symbols_with_data,
    }

def build_round_trades_from_positions(region: str):
    """
    positions í…Œì´ë¸” ê¸°ì¤€ìœ¼ë¡œ dash_auto.htmlì—ì„œ ì“°ëŠ” round_trades í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    conn = get_connection()
    try:
        if region == "ALL":
            df = pd.read_sql_query(
                """
                SELECT
                    id,
                    region,
                    symbol,
                    side,
                    qty,
                    entry_price,
                    entry_time,
                    closed_at,
                    is_open,
                    last_roi
                FROM positions
                ORDER BY entry_time DESC
                """,
                conn,
            )
        else:
            df = pd.read_sql_query(
                """
                SELECT
                    id,
                    region,
                    symbol,
                    side,
                    qty,
                    entry_price,
                    entry_time,
                    closed_at,
                    is_open,
                    last_roi
                FROM positions
                WHERE region = %s
                ORDER BY entry_time DESC
                """,
                conn,
                params=(region,),
            )
    finally:
        conn.close()

    if df.empty:
        # round_trades_df, round_details í˜•ì‹ì„ ë§ì¶°ì£¼ê¸° ìœ„í•´ íŠœí”Œ ë¦¬í„´
        return pd.DataFrame(), {}

    df["entry_time"] = pd.to_datetime(df["entry_time"])
    if "closed_at" in df.columns:
        df["closed_at"] = pd.to_datetime(df["closed_at"])

    rows = []
    for _, row in df.iterrows():
        entry_time = row.get("entry_time")
        exit_time = row.get("closed_at")
        side_raw = (row.get("side") or "").upper()
        qty = float(row.get("qty") or 0.0)
        entry_price = float(row.get("entry_price") or 0.0)

        status = "OPEN" if row.get("is_open") else "CLOSED"

        # data-date ì— ì“¸ ë‚ ì§œ (ì§„ì…ì¼ ê¸°ì¤€)
        if pd.notna(entry_time):
            date_str = entry_time.strftime("%Y-%m-%d")
        else:
            date_str = ""

        # last_roi: ì²­ì‚° ì‹œì  ì‹¤í˜„ ìˆ˜ìµë¥ (%) ë¼ê³  ê°€ì •
        roi = row.get("last_roi")
        try:
            realized_pct = float(roi) if roi is not None else 0.0
        except Exception:
            realized_pct = 0.0

        rows.append({
            "round_id": int(row.get("id")) if not pd.isna(row.get("id")) else None,
            "symbol": row.get("symbol"),
            "region": row.get("region"),

            "date": date_str,                            # âœ… data-date ìš©
            "entry_time": entry_time,                    # âœ… ê·¸ëŒ€ë¡œ ì°ì–´ë„ ë¨
            "exit_time": exit_time,                      # âœ… ì—†ìœ¼ë©´ None

            "status": status,                            # âœ… OPEN / CLOSED
            "entry_qty": qty,
            "entry_price": entry_price,
            "realized_profit_pct": realized_pct,         # âœ… "%.2f"|format() ëŒ€ìƒ

            # ë””í…Œì¼ í–‰ì—ì„œ ì“°ì§€ë§Œ ì—†ì–´ë„ ìë™ìœ¼ë¡œ ë¹„ì–´ ë‚˜ì˜´
            "entry_comment": None,
            "exit_comment": None,
        })

    round_trades_df = pd.DataFrame(rows)
    round_details = {}  # BIì—ì„  ì•„ì§ ì„¸ë¶€ ì²´ê²° ë¡œê·¸ ì•ˆ ì“°ë¯€ë¡œ ë¹ˆ dict

    return round_trades_df, round_details

# -----------------------------
# ì•± ì²´ê²° ë™ê¸°í™” ë¼ìš°íŠ¸
# -----------------------------
def sync_app_trades():
    return 0

@app.route("/sync-app-trades", methods=["POST"])
def sync_app_trades_route():
    try:
        inserted = sync_app_trades()
        return jsonify({"ok": True, "inserted": int(inserted)})
    except Exception as e:
        print("sync_app_trades ì˜¤ë¥˜:", e)
        return jsonify({"ok": False, "error": str(e)}), 500




# -----------------------------
# ì‹¬ë³¼ ì°¨íŠ¸ìš© ë°ì´í„° API (get_connection ì¬ì‚¬ìš©)
# -----------------------------
@app.route("/symbol_data")
def symbol_data():
    symbol = request.args.get("symbol")
    region_raw = request.args.get("region", "ALL")  # ì˜ˆ: KR, US, CR, BI ...
    if not symbol:
        return jsonify({"error": "symbol parameter required"}), 400

    region = (region_raw or "ALL").upper()

    conn = get_connection()
    try:
        # 1) ìº”ë“¤ ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
        candles = pd.read_sql_query(
            """
            SELECT dt, open, high, low, close
            FROM (
                SELECT dt, open, high, low, close
                FROM ohlcv_data
                WHERE symbol = %s
                  AND interval = '5m'
                ORDER BY dt DESC
                LIMIT 500
            ) t
            ORDER BY dt ASC
            """,
            conn,
            params=(symbol,),
        )

        # 2) í¬ì§€ì…˜ ê¸°ë°˜ ë§ˆì»¤ ë¡œë“œ
        #    - entry: entry_time / entry_price
        #    - exit : closed_at / exit_price (ë‹«íŒ í¬ì§€ì…˜ë§Œ)
        if region == "ALL":
            # region ìƒê´€ì—†ì´ í•´ë‹¹ ì‹¬ë³¼ì˜ ëª¨ë“  í¬ì§€ì…˜
            positions = pd.read_sql_query(
                """
                SELECT
                    region,
                    side,
                    qty,
                    entry_time,
                    entry_price,
                    closed_at,
                    exit_price,
                    is_open
                FROM positions
                WHERE symbol = %s
                  AND exchange = 'BINANCE'
                  AND market_type IN ('spot', 'futures')
                ORDER BY entry_time
                """,
                conn,
                params=(symbol,),
            )
        else:
            positions = pd.read_sql_query(
                """
                SELECT
                    region,
                    side,
                    qty,
                    entry_time,
                    entry_price,
                    closed_at,
                    exit_price,
                    is_open
                FROM positions
                WHERE symbol = %s
                  AND exchange = 'BINANCE'
                  AND region = %s
                  AND market_type IN ('spot', 'futures')
                ORDER BY entry_time
                """,
                conn,
                params=(symbol, region),
            )

    finally:
        conn.close()

    # ìº”ë“¤ì´ ì—†ìœ¼ë©´ ë°”ë¡œ ë¹ˆ ê°’ ë¦¬í„´
    if candles.empty:
        return jsonify({"candles": [], "trades": []})

    candles["dt"] = pd.to_datetime(candles["dt"])

    # 3) ìº”ë“¤ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ê³¼ ë™ì¼)
    candles_json = [
        {
            "time": row["dt"].strftime("%Y-%m-%d %H:%M"),
            "open": float(row["open"]),
            "high": float(row["high"]),
            "low": float(row["low"]),
            "close": float(row["close"]),
        }
        for _, row in candles.iterrows()
    ]

    # 4) positions â†’ ì—”íŠ¸ë¦¬/ì²­ì‚° ë§ˆì»¤ë¡œ ë³€í™˜
    trade_rows = []
    if not positions.empty:
        positions["entry_time"] = pd.to_datetime(positions["entry_time"])
        if "closed_at" in positions.columns:
            positions["closed_at"] = pd.to_datetime(positions["closed_at"])

        candle_times = candles["dt"].values

        # (1) ì—”íŠ¸ë¦¬ ë§ˆì»¤
        for _, row in positions.iterrows():
            et = row.get("entry_time")
            ep = row.get("entry_price")
            qty = row.get("qty", 0)
            side = (row.get("side") or "").upper()

            if pd.isna(et) or ep is None:
                continue

            # LONG/BUY â†’ BUY ë§ˆì»¤, SHORT â†’ SELL ë§ˆì»¤
            if side in ("LONG", "BUY"):
                m_type = "BUY"
            elif side in ("SHORT", "SELL"):
                m_type = "SELL"
            else:
                m_type = "BUY"

            tt = et.to_datetime64()
            pos = candle_times.searchsorted(tt, side="right") - 1
            if pos < 0 or pos >= len(candle_times):
                continue

            trade_rows.append(
                {
                    "x_index": int(pos),
                    "time": et.strftime("%Y-%m-%d %H:%M:%S"),
                    "type": m_type,
                    "price": float(ep),
                    "qty": float(abs(qty) if qty is not None else 0.0),
                }
            )

        # (2) ì²­ì‚° ë§ˆì»¤ (ë‹«íŒ í¬ì§€ì…˜ + exit_price ìˆëŠ” ê²ƒë§Œ)
        for _, row in positions.iterrows():
            ct = row.get("closed_at")
            xp = row.get("exit_price")
            qty = row.get("qty", 0)
            side = (row.get("side") or "").upper()
            is_open = row.get("is_open")

            if is_open:  # ì•„ì§ ì—´ë ¤ìˆëŠ” í¬ì§€ì…˜ì´ë©´ ì²­ì‚° ë§ˆì»¤ ì—†ì´ íŒ¨ìŠ¤
                continue
            if pd.isna(ct) or xp is None:
                continue

            # ì—”íŠ¸ë¦¬ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ í‘œì‹œ
            if side in ("LONG", "BUY"):
                m_type = "SELL"
            elif side in ("SHORT", "SELL"):
                m_type = "BUY"
            else:
                m_type = "SELL"

            tt = ct.to_datetime64()
            pos = candle_times.searchsorted(tt, side="right") - 1
            if pos < 0 or pos >= len(candle_times):
                continue

            trade_rows.append(
                {
                    "x_index": int(pos),
                    "time": ct.strftime("%Y-%m-%d %H:%M:%S"),
                    "type": m_type,
                    "price": float(xp),
                    "qty": float(abs(qty) if qty is not None else 0.0),
                }
            )

    # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ (ì—”íŠ¸ë¦¬/ì²­ì‚° ì„ì—¬ ìˆìœ¼ë¯€ë¡œ)
    trade_rows.sort(key=lambda x: x["time"])

    return jsonify(
        {
            "candles": candles_json,
            "trades": trade_rows,
        }
    )


# -----------------------------
# AI ë¦¬í¬íŠ¸ API (get_connection ì¬ì‚¬ìš©)
# -----------------------------
@app.route("/api/ai-report/full")
def api_ai_report_full():
    result = {
        "date": None,
        "created_at": None,
        "daily_report": "",
        "strategy_ideas": "",
        "model_advice_date": None,
        "model_advice": "",
    }

    # 1) ai_reports í…Œì´ë¸”ì—ì„œ ìµœì‹  1ê±´
    try:
        conn = get_connection()
        cur = conn.cursor()
        cur.execute(
            """
            SELECT date, created_at, daily_report, strategy_ideas
            FROM ai_reports
            ORDER BY date DESC, id DESC
            LIMIT 1
            """
        )
        row = cur.fetchone()
        conn.close()

        if row:
            result["date"] = row[0]
            result["created_at"] = row[1]
            result["daily_report"] = row[2] or ""
            result["strategy_ideas"] = row[3] or ""
    except Exception as e:
        print("ai_reports ì¡°íšŒ ì˜¤ë¥˜:", e)

    # 2) reports í´ë”ì˜ *_model_advice.txt
    try:
        os.makedirs("reports", exist_ok=True)
        files = glob(os.path.join("reports", "*_model_advice.txt"))
        if files:
            latest_file = max(files, key=os.path.getmtime)
            base = os.path.basename(latest_file)
            if base.endswith("_model_advice.txt"):
                date_part = base.replace("_model_advice.txt", "")
            else:
                date_part = None

            with open(latest_file, "r", encoding="utf-8") as f:
                text = f.read()

            result["model_advice_date"] = date_part
            result["model_advice"] = text
    except Exception as e:
        print("model_advice íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜:", e)

    return jsonify(result)


# -----------------------------
# ë¼ìš´íŠ¸: í˜ì´ì§€ë“¤
# -----------------------------
@app.route("/")
def root():
    region = normalize_region(request.args.get("region", "ALL"))
    return redirect(f"/dash/overview?region={region}")


@app.route("/dash/overview")
def dash_overview():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    return render_template(
        "dash_overview.html",
        page_title="ìš”ì•½ / ì„±ëŠ¥",
        active_page="overview",
        region=data["region"],
        summary=data["summary"],
        equity_curve=data["equity_curve"],
        symbols_avg=data["symbols_avg"],
        suggestions=data["suggestions"],
    )


@app.route("/dash/ai-report")
def dash_ai_report():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    return render_template(
        "dash_ai_report.html",
        page_title="AI ë¦¬í¬íŠ¸",
        active_page="ai-report",
        region=data["region"],
    )


@app.route("/dash/trades")
def dash_trades():
    region = normalize_region(request.args.get("region", "ALL"))
    return redirect(f"/dash/auto?region={region}")


@app.route("/dash/logs")
def dash_logs():
    region = normalize_region(request.args.get("region", "ALL"))
    return redirect(f"/dash/auto?region={region}")


@app.route("/dash/universe")
def dash_universe():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    return render_template(
        "dash_universe.html",
        page_title="Universe OHLCV",
        active_page="universe",
        region=data["region"],
        universe_cov=data["universe_cov"].to_dict(orient="records"),
        last_universe_backfill=data["last_universe_backfill"],
        universe_failures=data["universe_failures"].to_dict(orient="records"),
        num_universe_symbols=data["num_universe_symbols"],
        total_universe_candles=data["total_universe_candles"],
        max_days_covered=data["max_days_covered"],
    )


@app.route("/dash/ml")
def dash_ml():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    return render_template(
        "dash_ml.html",
        page_title="ML ëª¨ë‹ˆí„°ë§",
        active_page="ml",
        region=data["region"],
        ml_hist_labels=data["ml_hist_labels"],
        ml_hist_counts=data["ml_hist_counts"],
        ml_time_series=data["ml_time_series"],
        model_versions=data["model_versions"].to_dict(orient="records"),
        backtests=data["backtests"].to_dict(orient="records"),
    )


@app.route("/dash/symbols")
def dash_symbols():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    return render_template(
        "dash_symbols.html",
        page_title="ì¢…ëª©ë³„ ì°¨íŠ¸",
        active_page="symbols",
        region=data["region"],
        symbols_with_data=data["symbols_with_data"],
    )

@app.route("/dash/auto")
def dash_auto():
    region = request.args.get("region", "ALL")
    data = load_all_dashboard_data(region)
    sorted_round_trades = data["round_trades_df"].sort_values("entry_time", ascending=False)
    return render_template(
        "dash_auto.html",
        page_title="ìë™ë§¤ë§¤",
        active_page="auto",
        region=data["region"],
        universe_failures=data["universe_failures"].to_dict(orient="records"),
        # íŠ¸ë ˆì´ë“œìš©
        round_trades=sorted_round_trades.to_dict(orient="records"),
        round_details=data["round_details"],
        daily_summaries=data["daily_summaries"],
        summary=data["summary"],
        # ë¡œê·¸/ì‹ í˜¸ìš©
        logs=data["logs_recent"].to_dict(orient="records"),
        signals=data["signals"].to_dict(orient="records"),
        symbols_with_data=data["symbols_with_data"],
    )

if __name__ == "__main__":
    app.run(debug=True, port=8000)  