# bi_train_models.py
# ë©€í‹°ìŠ¤ì¼€ì¼ TCN ëª¨ë¸ í•™ìŠµ(train) ìŠ¤í¬ë¦½íŠ¸
import os
import torch
import torch.nn as nn
import time
from torch.utils.data import DataLoader
from datetime import datetime

import numpy as np             # âœ… ì´ë¯¸ main ì•ˆì—ì„œ ì“°ê³  ìˆì—ˆìœ¼ë©´ ìœ„ë¡œ ì˜¬ë ¤ë„ ë¨
import pandas as pd            # âœ… ì¶”ê°€

from c_config import BI_UNIVERSE_STOCKS
from bi_multiscale_loader import load_ohlcv_multiscale_for_symbol
from bi_create_dataset import MultiScaleOhlcvDatasetCR  # âœ… Datasetë§Œ
from bi_define_models import MultiScaleTCNTransformer
from bi_features import FEATURE_COLS, SEQ_LENS, HORIZONS, build_multiscale_samples_cr


DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ”§ ë¶„ë¥˜ ì†ì‹¤ ê°€ì¤‘ì¹˜ Î» (loss = loss_reg + Î» * loss_cls)
CLS_LOSS_WEIGHT = 1.0

def make_cls_labels(y: torch.Tensor) -> torch.Tensor:
    """
    íšŒê·€ íƒ€ê²Ÿ y (ìˆ˜ìµë¥ , shape: (B, H)) ë¡œë¶€í„°
    ë¶„ë¥˜ìš© ë¼ë²¨ ìƒì„±: y > 0 ì´ë©´ 1, ì•„ë‹ˆë©´ 0
    """
    return (y > 0).float()

def load_positions_all() -> pd.DataFrame:
    """
    positions ì „ì²´ë¥¼ DataFrameìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” í—¬í¼.
    - region='BI' ë§Œ ì‚¬ìš©í•˜ëŠ” ê²Œ ìì—°ìŠ¤ëŸ¬ì›€.
    - ì‹¤ì œ êµ¬í˜„ì€ ë„¤ê°€ ì“°ëŠ” DB/í´ë¼ì´ì–¸íŠ¸ì— ë§ì¶° ì±„ìš°ë©´ ë¨.
    """
    # ì˜ˆì‹œ) ë§Œì•½ Supabase/Postgresë¥¼ ì§ì ‘ ì—°ê²°í•œë‹¤ë©´ ì—¬ê¸°ì„œ ì½ê¸°
    # ì•„ë˜ëŠ” 'ì§ì ‘ êµ¬í˜„ í•„ìš”'ì¸ ìë¦¬ í‘œì‹œì
    # return pd.read_sql("SELECT * FROM public.positions WHERE region = 'BI';", conn)

    raise NotImplementedError("load_positions_all() ì•ˆì„ ì‹¤ì œ DB ì½”ë“œë¡œ êµ¬í˜„í•˜ì„¸ìš”.")

def build_trade_labels_for_symbol(base_dt_array, positions_sym_df: pd.DataFrame):
    """
    base_dt_array: build_multiscale_samples_cr(..., return_index=True) ì—ì„œ ë°›ì€ (N,) dt ë°°ì—´
    positions_sym_df: í•´ë‹¹ symbol í¬ì§€ì…˜ë“¤ (region/symbol í•„í„° í›„)

    ë°˜í™˜:
      y_trade   : (N,) float32,  0.0/1.0
      trade_mask: (N,) float32,  0.0/1.0   (í¬ì§€ì…˜ ë¼ë²¨ì´ ìˆëŠ” ì‹œì ë§Œ 1)
    """
    # 1) ë‹«íŒ í¬ì§€ì…˜ + pnl_pct/entry_time ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©
    pos = positions_sym_df.copy()
    pos = pos[
        (pos["status"] == "CLOSED")
        & (~pos["pnl_pct"].isna())
        & (~pos["entry_time"].isna())
    ]

    N = len(base_dt_array)
    if pos.empty:
        # ì´ ì‹¬ë³¼ì— ì“¸ í¬ì§€ì…˜ ë¼ë²¨ ì—†ìŒ
        return np.zeros(N, dtype=np.float32), np.zeros(N, dtype=np.float32)

    # 2) entry_time â†’ KST ê¸°ì¤€ 5ë¶„ë´‰ íƒ€ì„ìŠ¤í…ìœ¼ë¡œ ì •ë ¬
    pos["entry_time"] = pd.to_datetime(pos["entry_time"], utc=True)
    pos["entry_kst"] = pos["entry_time"].dt.tz_convert("Asia/Seoul")
    pos["entry_5m"] = pos["entry_kst"].dt.floor("5min")

    # 3) entry_5m ì‹œì ë³„ë¡œ ë¼ë²¨ ë§¤í•‘
    #    pnl_pct > 0 â†’ 1.0, else 0.0
    label_map = {}
    for _, row in pos.iterrows():
        dt = row["entry_5m"]
        pnl_pct = float(row["pnl_pct"])
        label = 1.0 if pnl_pct > 0 else 0.0
        # í•œ ì‹œì ì— í¬ì§€ì…˜ ì—¬ëŸ¬ ê°œë©´ ë§ˆì§€ë§‰ ê²ƒ ê¸°ì¤€(í•„ìš”í•˜ë©´ í‰ê·  ë“±ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
        label_map[dt] = label

    # 4) base_dt_array ìˆœì„œëŒ€ë¡œ y_trade / mask ì±„ìš°ê¸°
    base_dt_series = pd.to_datetime(base_dt_array)

    y_trade = np.zeros(N, dtype=np.float32)
    trade_mask = np.zeros(N, dtype=np.float32)

    for i, dt in enumerate(base_dt_series):
        # df_5m.index ëŠ” ë³´í†µ naive KST datetime â†’ tz_localize í•„ìš”
        if dt.tzinfo is None:
            dt_kst = dt.tz_localize("Asia/Seoul")
        else:
            dt_kst = dt.tz_convert("Asia/Seoul")

        if dt_kst in label_map:
            y_trade[i] = label_map[dt_kst]
            trade_mask[i] = 1.0

    return y_trade, trade_mask

def main():
    # =====================
    # 1) ë°ì´í„° ëª¨ìœ¼ê¸°
    # =====================
    feature_cols = FEATURE_COLS 
    seq_lens = SEQ_LENS           
    horizons = HORIZONS          

    try:
        positions_all = load_positions_all()
    except NotImplementedError:
        # ì•„ì§ êµ¬í˜„ ì•ˆ í–ˆìœ¼ë©´ positions ì—†ì´ í•™ìŠµ (ê¸°ì¡´ ë°©ì‹)
        positions_all = None
        print("[WARN] load_positions_all()ê°€ êµ¬í˜„ë˜ì§€ ì•Šì•„ positions ê¸°ë°˜ ë¼ë²¨ ì—†ì´ í•™ìŠµí•©ë‹ˆë‹¤.")

    X5_list_all = []
    X15_list_all = []
    X30_list_all = []
    X1h_list_all = []
    Y_list_all = []
    y_trade_list_all = []
    trade_mask_list_all = []
    
    total_count = len(BI_UNIVERSE_STOCKS)
    print(f"ğŸš€ [Start] ì´ {total_count}ê°œ ì½”ì¸ ë°ì´í„° ë¡œë”© ì‹œì‘...")

    for i, t in enumerate(BI_UNIVERSE_STOCKS):
        region = t["region"]
        symbol = t["symbol"]

        print(f"  -> [{i+1}/{total_count}] {symbol} ë°ì´í„° ì²˜ë¦¬ ì¤‘...", end="\r")

        try:
            df_5m, df_15m, df_30m, df_1h = load_ohlcv_multiscale_for_symbol(
                region=region,
                symbol=symbol,
                base_interval="5m",
            )
        except ValueError as e:
            print(f"[WARN] {region} {symbol} OHLCV ë¡œë”© ì‹¤íŒ¨: {e}")
            continue

        try:
            X_5m, X_15m, X_30m, X_1h, Y, base_dt = build_multiscale_samples_cr(
                df_5m=df_5m,
                df_15m=df_15m,
                df_30m=df_30m,
                df_1h=df_1h,
                feature_cols=feature_cols,
                seq_lens=seq_lens,
                horizons=horizons,
                return_index=True,
            )
        except ValueError as e:
            print(f"[WARN] {region} {symbol} ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨: {e}")
            continue

        X5_list_all.append(X_5m)
        X15_list_all.append(X_15m)
        X30_list_all.append(X_30m)
        X1h_list_all.append(X_1h)
        Y_list_all.append(Y)

        # âœ… ì´ ì‹¬ë³¼ì— í•´ë‹¹í•˜ëŠ” positions ì¶”ì¶œ & ë¼ë²¨ ìƒì„±
        if positions_all is not None:
            pos_sym = positions_all[
                (positions_all["region"] == region)
                & (positions_all["symbol"] == symbol)
            ]
            y_trade_sym, trade_mask_sym = build_trade_labels_for_symbol(
                base_dt, pos_sym
            )
        else:
            # positionsë¥¼ ì•„ì§ ì•ˆ ì“°ëŠ” ê²½ìš°: 0ìœ¼ë¡œ ì±„ìš°ê¸° (ì‚¬ì‹¤ìƒ trade_loss=0ì´ ë¨)
            y_trade_sym = np.zeros(len(Y), dtype=np.float32)
            trade_mask_sym = np.zeros(len(Y), dtype=np.float32)
            
        # âœ… ë¼ë²¨ë„ í•¨ê»˜ ëª¨ìœ¼ê¸°
        y_trade_list_all.append(y_trade_sym)
        trade_mask_list_all.append(trade_mask_sym)

    if not X5_list_all:
        raise RuntimeError("BI_UNIVERSE_STOCKS ì „ì²´ì—ì„œ ìœ íš¨í•œ ìƒ˜í”Œì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")

    X_5m = np.concatenate(X5_list_all, axis=0)
    X_15m = np.concatenate(X15_list_all, axis=0)
    X_30m = np.concatenate(X30_list_all, axis=0)
    X_1h = np.concatenate(X1h_list_all, axis=0)
    Y = np.concatenate(Y_list_all, axis=0)

    # âœ… í¬ì§€ì…˜ ë¼ë²¨ë„ concat
    y_trade_all = np.concatenate(y_trade_list_all, axis=0)
    trade_mask_all = np.concatenate(trade_mask_list_all, axis=0)

    dataset = MultiScaleOhlcvDatasetCR(
        X_5m, X_15m, X_30m, X_1h, Y,
        y_trade=y_trade_all,
        trade_mask=trade_mask_all,
    )

    # ğŸ” ë°ì´í„° ìš”ì•½ ë¡œê·¸
    print("")
    print("âœ… [DATA SUMMARY]")
    print(f"  - ì´ ì‹¬ë³¼ ìˆ˜: {len(X5_list_all)}")
    print(f"  - ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset)}")
    print(f"  - 5m ì‹œí€€ìŠ¤ shape: {X_5m.shape}")
    print(f"  - Y shape: {Y.shape}")
    print(f"  - Y í†µê³„: mean={Y.mean():.6f}, std={Y.std():.6f}", flush=True)

    # =====================
    # 2) train / val split
    # =====================
    n_total = len(dataset)
    n_train = int(n_total * 0.8)
    n_val = n_total - n_train 

    indices = torch.arange(n_total)

    train_indices = indices[:n_train]
    val_indices = indices[n_train:]

    train_set = torch.utils.data.Subset(dataset, train_indices)
    val_set = torch.utils.data.Subset(dataset, val_indices)

    print("âœ… [SPLIT]")
    print(f"  - train ìƒ˜í”Œ: {n_train}")
    print(f"  - val ìƒ˜í”Œ:   {n_val}", flush=True)

    # [ìˆ˜ì •] batch_sizeë¥¼ 64 -> 512 ë˜ëŠ” 1024ë¡œ ëŠ˜ë¦¬ì„¸ìš”. (í•™ìŠµ ì†ë„ ëŒ€í­ í–¥ìƒ)
    # [ìˆ˜ì •] num_workersë¥¼ 0 -> 4 ì •ë„ë¡œ ì„¤ì •í•˜ì„¸ìš”. (CPU ì½”ì–´ í™œìš©)
    # ë‹¨, Windowsì—ì„œëŠ” num_workers > 0 ì¼ ë•Œ ì—ëŸ¬ê°€ ë‚  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. 
    # ì—ëŸ¬ ë‚˜ë©´ ë‹¤ì‹œ 0ìœ¼ë¡œ, ì•ˆ ë‚˜ë©´ 4ê°€ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤.
    
    train_loader = DataLoader(train_set, batch_size=512, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_set, batch_size=512, shuffle=False, num_workers=0)

    # =====================
    # 3) ëª¨ë¸ ì¤€ë¹„
    # =====================
    in_features = len(feature_cols)

    model = MultiScaleTCNTransformer(
        in_features=in_features,
        horizons=horizons,
        hidden_channels=64,
        tcn_layers_per_scale=4,
        transformer_layers=2,
        nhead=4,
        dropout=0.1,
        use_classification=True,  # íšŒê·€ + ë¶„ë¥˜ ë©€í‹°íƒœìŠ¤í¬
        use_trade_head=True, 
    ).to(DEVICE)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    loss_reg_fn = nn.SmoothL1Loss()
    loss_cls_fn = nn.BCEWithLogitsLoss()

    # âœ… í¬ì§€ì…˜ ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜ìš© loss (ë§ˆìŠ¤í¬ë¥¼ ì”Œì›Œì•¼ í•´ì„œ reduction='none')
    loss_trade_fn = nn.BCEWithLogitsLoss(reduction="none")
    TRADE_LOSS_WEIGHT = 0.5  # ì²˜ìŒì—” 0.2~0.5 ì •ë„ë¡œ ì‹œì‘ ì¶”ì²œ

    save_dir = "models"
    os.makedirs(save_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = os.path.join(save_dir, f"multiscale_BI_model_{timestamp}.pth")

    # =====================
    # 4) í•™ìŠµ ë£¨í”„
    # =====================
    num_epochs = 30
    best_val_loss = float("inf")

    for epoch in range(1, num_epochs + 1):
        epoch_start = time.time()
        model.train()
        total_loss = 0.0
        total_reg_loss = 0.0
        total_trade_loss = 0.0
        total_cls_loss = 0.0
        total_cls_correct = 0.0
        total_cls_elems = 0

        for batch in train_loader:
            x_5m = batch["x_5m"].to(DEVICE)
            x_15m = batch["x_15m"].to(DEVICE)
            x_30m = batch["x_30m"].to(DEVICE)
            x_1h = batch["x_1h"].to(DEVICE)
            y = batch["y"].to(DEVICE)  # (B, H)

            y_cls = make_cls_labels(y)  # (B, H)

            # âœ… í¬ì§€ì…˜ ë¼ë²¨/ë§ˆìŠ¤í¬ (ì—†ì„ ìˆ˜ë„ ìˆì–´ì„œ get ì‚¬ìš©)
            y_trade = batch.get("y_trade")
            trade_mask = batch.get("trade_mask")
            if y_trade is not None:
                y_trade = y_trade.to(DEVICE)         # (B,)
                trade_mask = trade_mask.to(DEVICE)   # (B,)

            optimizer.zero_grad()
            out = model(x_5m, x_15m, x_30m, x_1h)

            pred_reg = out["reg"]       # (B, H)
            logits = out["logits"]      # (B, H)

            loss_reg = loss_reg_fn(pred_reg, y)
            loss_cls = loss_cls_fn(logits, y_cls)

            # âœ… ê¸°ë³¸ loss
            loss = loss_reg + CLS_LOSS_WEIGHT * loss_cls

            # âœ… trade headê°€ ìˆê³ , y_tradeê°€ ìˆì„ ë•Œë§Œ trade loss ì¶”ê°€
            trade_loss = torch.tensor(0.0, device=DEVICE)
            if y_trade is not None and "trade_logits" in out:
                trade_logits = out["trade_logits"]      # (B,)
                raw_trade_loss = loss_trade_fn(trade_logits, y_trade)  # (B,)
                # ë§ˆìŠ¤í¬ ì ìš©í•´ì„œ ë¼ë²¨ ìˆëŠ” ì‹œì ë§Œ í‰ê· 
                trade_loss = (raw_trade_loss * trade_mask).sum() / (trade_mask.sum() + 1e-6)
                loss = loss + TRADE_LOSS_WEIGHT * trade_loss

            loss.backward()
            optimizer.step()

            B = y.size(0)

            total_loss += loss.item() * B
            total_reg_loss += loss_reg.item() * B
            total_cls_loss += loss_cls.item() * B
            total_trade_loss += trade_loss.item() * B 

            # ë¶„ë¥˜ ì •í™•ë„ ê³„ì‚°
            with torch.no_grad():
                prob = torch.sigmoid(logits)              # (B, H)
                pred_bin = (prob >= 0.5).float()          # (B, H)
                correct = (pred_bin == y_cls).float().sum().item()
                total_cls_correct += correct
                total_cls_elems += y_cls.numel()

        avg_train_loss = total_loss / n_train
        avg_train_reg_loss = total_reg_loss / n_train
        avg_train_cls_loss = total_cls_loss / n_train
        train_cls_acc = total_cls_correct / total_cls_elems if total_cls_elems > 0 else 0.0
        avg_train_trade_loss = total_trade_loss / n_train
        # ----- validation -----
        model.eval()
        val_loss = 0.0
        val_reg_loss = 0.0
        val_cls_loss = 0.0
        val_cls_correct = 0.0
        val_cls_elems = 0

        with torch.no_grad():
            for batch in val_loader:
                x_5m = batch["x_5m"].to(DEVICE)
                x_15m = batch["x_15m"].to(DEVICE)
                x_30m = batch["x_30m"].to(DEVICE)
                x_1h = batch["x_1h"].to(DEVICE)
                y = batch["y"].to(DEVICE)

                y_cls = make_cls_labels(y)

                out = model(x_5m, x_15m, x_30m, x_1h)
                pred_reg = out["reg"]
                logits = out["logits"]

                loss_reg = loss_reg_fn(pred_reg, y)
                loss_cls = loss_cls_fn(logits, y_cls)
                loss = loss_reg + CLS_LOSS_WEIGHT * loss_cls

                B = y.size(0)
                val_loss += loss.item() * B
                val_reg_loss += loss_reg.item() * B
                val_cls_loss += loss_cls.item() * B

                prob = torch.sigmoid(logits)
                pred_bin = (prob >= 0.5).float()
                correct = (pred_bin == y_cls).float().sum().item()
                val_cls_correct += correct
                val_cls_elems += y_cls.numel()

        avg_val_loss = val_loss / n_val
        avg_val_reg_loss = val_reg_loss / n_val
        avg_val_cls_loss = val_cls_loss / n_val
        val_cls_acc = val_cls_correct / val_cls_elems if val_cls_elems > 0 else 0.0

        epoch_sec = time.time() - epoch_start

        print(
            f"[Epoch {epoch}/{num_epochs}] "
            f"train_loss={avg_train_loss:.6f} "
            f"(reg={avg_train_reg_loss:.6f}, cls={avg_train_cls_loss:.6f}, trade={avg_train_trade_loss:.6f}, acc={train_cls_acc*100:.2f}%) | "
            f"val_loss={avg_val_loss:.6f} "
            f"(reg={avg_val_reg_loss:.6f}, cls={avg_val_cls_loss:.6f}, acc={val_cls_acc*100:.2f}%) | "
            f"time={epoch_sec:.1f}s",
            flush=True,
        )

        # ëª¨ë¸ ì €ì¥ ê¸°ì¤€ì€ ì „ì²´ loss ê¸°ì¤€ (í•„ìš”í•˜ë©´ reg_loss ê¸°ì¤€ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), save_path)
            print(f"  Best model updated: {save_path} (val_loss={avg_val_loss:.6f})")


if __name__ == "__main__":
    main()
