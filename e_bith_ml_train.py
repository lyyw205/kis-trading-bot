# ì‹œí€€ìŠ¤ ê¸°ë°˜ ê³µìš© ML ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

# - ml_seq_samples í…Œì´ë¸” + ohlcv_data í…Œì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œí€€ìŠ¤ í”¼ì²˜ë¥¼ ë§Œë“¤ê³ 
#   RandomForestClassifierë¥¼ í•™ìŠµÂ·í‰ê°€Â·ë²„ì „ ê´€ë¦¬ê¹Œì§€ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê³µìš© íŠ¸ë ˆì´ë„ˆ

# ì£¼ìš” ê¸°ëŠ¥:
# 1) load_ml_seq_samples()
#    : trading.db ì˜ ml_seq_samples í…Œì´ë¸”ì—ì„œ í•™ìŠµ ìƒ˜í”Œ(label í¬í•¨) ë¡œë“œ

# 2) load_all_ohlcv()
#    : ohlcv_data í…Œì´ë¸”ì—ì„œ region/symbol/intervalë³„ OHLCVë¥¼ ëª¨ë‘ ë¡œë“œí•´
#      (region, symbol, interval)ì„ keyë¡œ í•˜ëŠ” dictë¡œ ë°˜í™˜

# 3) make_config_hash(cfg)
#    : í•™ìŠµ ì„¤ì •/ë©”íƒ€ë°ì´í„° dictë¥¼ JSON ì§ë ¬í™” â†’ sha256 í•´ì‹œ â†’ ì• 10ìë¦¬ë¡œ ì••ì¶•í•œ
#      CONFIG_HASH ìƒì„± (ëª¨ë¸ ë²„ì „ ì¶”ì ìš©)

# 4) train_seq_model_for_universe(universe, region_filter, model_setting_key, ...)
#    : ìœ ë‹ˆë²„ìŠ¤/region ê¸°ì¤€ìœ¼ë¡œ ìƒ˜í”Œ í•„í„°ë§ â†’ ml_features.build_feature_from_seqë¡œ í”¼ì²˜ ìƒì„±
#      â†’ RandomForestClassifier í•™ìŠµ/ê²€ì¦
#      â†’ pkl ëª¨ë¸ íŒŒì¼ ì €ì¥ + ë™ì¼ ê²½ë¡œì˜ .meta.jsonì— í•™ìŠµ ì„¤ì •/í•´ì‹œ/ì •í™•ë„ ê¸°ë¡
#      â†’ models í…Œì´ë¸”ì— ë²„ì „ row ì¶”ê°€
#      â†’ settings í…Œì´ë¸”ì˜ model_setting_key ê°’(í™œì„± ëª¨ë¸ ê²½ë¡œ) ì—…ë°ì´íŠ¸

import os
import json
import hashlib
import sqlite3
from datetime import datetime

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import joblib

from c_db_manager import BotDatabase
from c_ml_features import SEQ_LEN, build_feature_from_seq  # ê³µí†µ ëª¨ë“ˆ

DB_PATH = "trading.db"


# -----------------------------------------------------------
# 0) ì„¤ì • í•´ì‹œ ìœ í‹¸
# -----------------------------------------------------------
def make_config_hash(cfg: dict) -> str:
    cfg_json = json.dumps(cfg, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(cfg_json.encode("utf-8")).hexdigest()[:10]


# -----------------------------------------------------------
# 1) í•™ìŠµìš© ìƒ˜í”Œ / OHLCV ë¡œë”©
# -----------------------------------------------------------
def load_ml_seq_samples() -> pd.DataFrame:
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("SELECT * FROM ml_seq_samples", conn)
    conn.close()
    return df


def load_all_ohlcv() -> dict:
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query(
        """
        SELECT region, symbol, interval, dt, open, high, low, close, volume
        FROM ohlcv_data
        ORDER BY region, symbol, interval, dt
        """,
        conn,
    )
    conn.close()

    if df.empty:
        return {}

    df["dt"] = pd.to_datetime(df["dt"])

    groups = {}
    for (region, symbol, interval), g in df.groupby(
        ["region", "symbol", "interval"], sort=False
    ):
        g = g.copy().sort_values("dt")
        g.set_index("dt", inplace=True)

        g = g[["open", "high", "low", "close", "volume"]].apply(
            pd.to_numeric, errors="coerce"
        ).dropna()

        if g.empty:
            continue

        groups[(region, symbol, interval)] = g

    return groups


# -----------------------------------------------------------
# 2) ì½”ì¸(CR/BI) ì „ìš© í•™ìŠµ í•¨ìˆ˜
# -----------------------------------------------------------
def train_seq_model_for_coin_universe(
    universe: list[dict],
    *,
    region_filter: str | None,  # "CR", "BI" ë˜ëŠ” None(ì½”ì¸ ì „ì²´)
    model_setting_key: str,
    note_prefix: str = "[COIN] ",
    model_dir: str = "models_coin",
    extra_config: dict | None = None,
):
    """
    ì½”ì¸ ìœ ë‹ˆë²„ìŠ¤(CR / BI)ì— ëŒ€í•´ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•˜ëŠ” ì „ìš© í•¨ìˆ˜.

    - universe: [{"region": "CR"/"BI", "symbol": "...", ...}, ...]
      * CR  : ë¹—ì¸(ë˜ëŠ” ê¸°ì¡´ ì½”ì¸ ì—”ì§„)
      * BI  : ë°”ì´ë‚¸ìŠ¤ (ì›í•˜ë©´ BI ì „ìš©ìœ¼ë¡œë„ í•™ìŠµ ê°€ëŠ¥)
    - region_filter:
        - "CR": ë¹—ì¸ ì½”ì¸ ì „ìš© ëª¨ë¸
        - "BI": ë°”ì´ë‚¸ìŠ¤ ì½”ì¸ ì „ìš© ëª¨ë¸
        - None: CR + BI ì „ì²´ ì½”ì¸ í•œ ëª¨ë¸ë¡œ í•™ìŠµ
    - model_setting_key: settingsì— ì €ì¥í•  í‚¤ (ì˜ˆ: active_model_path_coin, active_model_path_bi)
    - note_prefix: ë¡œê·¸/íŒŒì¼ëª… ì ‘ë‘ì–´ (ì˜ˆ: "[COIN_CR] ", "[COIN_BI] ")
    - model_dir: ì½”ì¸ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: models_coin)
    - extra_config: ì—”íŠ¸ë¦¬/ì²­ì‚° ë£° ë²„ì „ ë“± ë©”íƒ€ë°ì´í„° dict
    """
    os.makedirs(model_dir, exist_ok=True)
    db = BotDatabase(DB_PATH)
    db.log(f"{note_prefix}ğŸ§  [COIN] ì‹œí€€ìŠ¤ ê¸°ë°˜ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘ (setting_key={model_setting_key})")

    # 1) ìƒ˜í”Œ ë¡œë“œ
    df_samples = load_ml_seq_samples()
    if df_samples.empty:
        print("ml_seq_samples í…Œì´ë¸”ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ml_build_seq_samples.py ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # label 0/1ë§Œ ì‚¬ìš©
    df_samples = df_samples[df_samples["label"].isin([0, 1])].copy()
    if df_samples.empty:
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ë¼ë²¨(0/1)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1-1) ì½”ì¸ ì „ìš© region í•„í„° (CR, BI)
    df_samples = df_samples[df_samples["region"].isin(["CR", "BI"])].copy()
    if df_samples.empty:
        print("[COIN] CR/BI ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    if region_filter is not None:
        if region_filter not in ("CR", "BI"):
            print(f"[COIN] region_filterëŠ” CR ë˜ëŠ” BI ë˜ëŠ” Noneë§Œ í—ˆìš©ë©ë‹ˆë‹¤. (ì…ë ¥: {region_filter})")
            return

        before = len(df_samples)
        df_samples = df_samples[df_samples["region"] == region_filter].copy()
        after = len(df_samples)
        print(f"[COIN] region={region_filter} í•„í„°: {before} â†’ {after}")
        if df_samples.empty:
            print(f"[COIN] region={region_filter} ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
            return

    # 1-2) universeì— í¬í•¨ëœ ì¢…ëª©ë§Œ ë‚¨ê¸°ê¸°
    universe_pairs = {(s["region"], s["symbol"]) for s in universe}
    before_cnt = len(df_samples)
    df_samples = df_samples[
        df_samples[["region", "symbol"]]
        .apply(lambda r: (r["region"], r["symbol"]) in universe_pairs, axis=1)
    ].copy()
    after_cnt = len(df_samples)

    print(f"[COIN] UNIVERSE í•„í„° ì „ ìƒ˜í”Œ ìˆ˜: {before_cnt}")
    print(f"[COIN] UNIVERSE í•„í„° í›„ ìƒ˜í”Œ ìˆ˜: {after_cnt}")

    if df_samples.empty:
        print("[COIN] UNIVERSEì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2) OHLCV ì „ì²´ ë¡œë“œ
    ohlcv_dict = load_all_ohlcv()
    if not ohlcv_dict:
        print("ohlcv_data í…Œì´ë¸”ì´ ë¹„ì–´ ìˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    X_list = []
    y_list = []
    skip_count = 0

    # 3) ê° ìƒ˜í”Œì— ëŒ€í•´ ì‹œí€€ìŠ¤ í”¼ì²˜ êµ¬ì„±
    for _, row in df_samples.iterrows():
        region = row["region"]
        symbol = row["symbol"]
        interval = row["interval"]
        dt_entry_str = row["dt_entry"]
        label = int(row["label"])

        key = (region, symbol, interval)
        if key not in ohlcv_dict:
            skip_count += 1
            continue

        df_ohlcv = ohlcv_dict[key]

        dt_entry = pd.to_datetime(dt_entry_str)
        if dt_entry not in df_ohlcv.index:
            skip_count += 1
            continue

        pos = df_ohlcv.index.get_loc(dt_entry)
        if isinstance(pos, slice):
            pos = pos.stop - 1

        if pos < SEQ_LEN - 1:
            skip_count += 1
            continue

        df_seq = df_ohlcv.iloc[pos - SEQ_LEN + 1 : pos + 1]
        feat = build_feature_from_seq(df_seq)
        if feat is None:
            skip_count += 1
            continue

        X_list.append(feat)
        y_list.append(label)

    if not X_list:
        print("[COIN] ìœ íš¨í•œ í”¼ì²˜ë¥¼ ê°€ì§„ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    X = np.array(X_list, dtype=float)
    y = np.array(y_list, dtype=int)

    print(f"[COIN] í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ìƒ˜í”Œ ìˆ˜: {len(X)}")
    print(f"[COIN] ìŠ¤í‚µëœ ìƒ˜í”Œ ìˆ˜: {skip_count}")
    print(f"[COIN] í”¼ì²˜ ì°¨ì›: {X.shape[1]}")

    # 4) Train / Test split
    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=0.2,
        random_state=42,
        stratify=y,
    )

    # 5) ëª¨ë¸ í•™ìŠµ
    rf_params = {
        "n_estimators": 300,
        "max_depth": None,
        "min_samples_split": 5,
        "min_samples_leaf": 3,
        "random_state": 42,
        "n_jobs": -1,
    }

    model = RandomForestClassifier(**rf_params)
    model.fit(X_train, y_train)

    # 6) í‰ê°€
    y_pred = model.predict(X_test)
    print(f"{note_prefix}=== [COIN] Classification Report ===")
    print(classification_report(y_test, y_pred, digits=4))

    print(f"{note_prefix}=== [COIN] Confusion Matrix ===")
    print(confusion_matrix(y_test, y_pred))

    accuracy = float((y_pred == y_test).mean())
    print(f"{note_prefix}[COIN] Validation Accuracy: {accuracy:.4f}")

    # 7) ëª¨ë¸ íŒŒì¼ëª…/ê²½ë¡œ ìƒì„±
    now = datetime.now()
    version_str = now.strftime("%Y%m%d_%H%M%S")

    tag = note_prefix.strip("[] ").replace(" ", "_").lower()
    tag = f"{tag}_" if tag else ""
    model_filename = f"seq_model_coin_{tag}{version_str}.pkl"

    model_path = os.path.join(model_dir, model_filename)

    # -------------------------------------------------------
    # 7-1) í•™ìŠµ ì„¤ì • ë©”íƒ€ë°ì´í„° êµ¬ì„± + í•´ì‹œ ìƒì„±
    # -------------------------------------------------------
    uni_list = sorted({(u["region"], u["symbol"]) for u in universe})

    train_config = {
        "project": "kis-trading-bot",
        "asset_class": "COIN",
        "region_filter": region_filter,
        "model_setting_key": model_setting_key,
        "seq_len": SEQ_LEN,
        "rf_params": rf_params,
        "universe_size": len(uni_list),
        "universe_sample": uni_list[:50],
        "sample_table": "ml_seq_samples",
        "ohlcv_table": "ohlcv_data",
        "created_at": now.strftime("%Y-%m-%d %H:%M:%S"),
    }

    if extra_config:
        train_config.update(extra_config)

    config_hash = make_config_hash(train_config)

    # 8) ëª¨ë¸ ì €ì¥
    joblib.dump(model, model_path)
    print(f"{note_prefix}[COIN] ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    print(f"{note_prefix}[COIN] CONFIG_HASH: {config_hash}")

    # 8-1) ë©”íƒ€ë°ì´í„° JSON ì €ì¥
    meta_path = model_path.replace(".pkl", ".meta.json")
    meta = {
        "model_path": model_path,
        "config": train_config,
        "config_hash": config_hash,
        "n_samples": int(len(X)),
        "val_accuracy": accuracy,
    }

    try:
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        print(f"{note_prefix}[COIN] ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {meta_path}")
    except Exception as e:
        print(f"{note_prefix}[COIN] ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    note_text = f"{note_prefix}region={region_filter}" if region_filter else note_prefix
    note_text = f"{note_text} cfg={config_hash}"

    # 9) models í…Œì´ë¸”ì— ë²„ì „ ê¸°ë¡
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute(
            """
            INSERT INTO models (created_at, path, n_samples, val_accuracy, note)
            VALUES (?, ?, ?, ?, ?)
            """,
            (
                now.strftime("%Y-%m-%d %H:%M:%S"),
                model_path,
                int(len(X)),
                accuracy,
                note_text,
            ),
        )
        conn.commit()
        conn.close()
        db.log(f"{note_prefix}[COIN] models í…Œì´ë¸”ì— ë²„ì „ ê¸°ë¡ ì™„ë£Œ: {model_path}")
    except Exception as e:
        db.log(f"{note_prefix}[COIN] models í…Œì´ë¸” ê¸°ë¡ ì‹¤íŒ¨: {e}")

    # 10) settings ì— model_setting_key ê°±ì‹ 
    try:
        db.set_setting(model_setting_key, model_path)
        db.log(f"{note_prefix}[COIN] {model_setting_key} ê°±ì‹ : {model_path}")
    except Exception as e:
        db.log(f"{note_prefix}[COIN] {model_setting_key} ê°±ì‹  ì‹¤íŒ¨: {e}")

    db.log(
        f"{note_prefix}âœ… [COIN] ì‹œí€€ìŠ¤ ê¸°ë°˜ ML ëª¨ë¸ í•™ìŠµ/ì €ì¥ ì™„ë£Œ "
        f"(accuracy={accuracy:.4f}, cfg={config_hash})"
    )

    return model_path, accuracy, len(X)